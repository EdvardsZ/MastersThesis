{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=100, shuffle=True)\n",
    "\n",
    "val_dataset = torchvision.datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, x_dim: int, h_dim1: int, h_dim2: int, z_dim: int):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # encoder part\n",
    "        self.fc1 = nn.Linear(x_dim, h_dim1)\n",
    "        self.fc2 = nn.Linear(h_dim1, h_dim2)\n",
    "        self.fc31 = nn.Linear(h_dim2, z_dim)\n",
    "        self.fc32 = nn.Linear(h_dim2, z_dim)\n",
    "        # decoder part\n",
    "        self.fc4 = nn.Linear(z_dim, h_dim2)\n",
    "        self.fc5 = nn.Linear(h_dim2, h_dim1)\n",
    "        self.fc6 = nn.Linear(h_dim1, x_dim)\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return self.fc31(h), self.fc32(h) # mu, log_var\n",
    "    \n",
    "    def sampling(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu) # return z sample\n",
    "        \n",
    "    def decoder(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        h = F.relu(self.fc5(h))\n",
    "        return F.sigmoid(self.fc6(h)) \n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        mu, log_var = self.encoder(x.view(-1, 784))\n",
    "        z = self.sampling(mu, log_var)\n",
    "        return self.decoder(z), mu, log_var\n",
    "\n",
    "    def loss(self, batch, outputs):\n",
    "        x, y = batch\n",
    "        x_recon, mean, log_var  = outputs\n",
    "\n",
    "        BCE = recon_loss(x_recon, x.view(-1, 784))\n",
    "        KLD = kl_loss(mean, log_var)\n",
    "        \n",
    "        loss = BCE + KLD\n",
    "\n",
    "        return { 'loss': loss, 'recon_loss_0': BCE, 'kl_loss': KLD}\n",
    "    \n",
    "def kl_loss(z_mean, z_log_var):\n",
    "        return -0.5 * torch.sum(1 + z_log_var - z_mean.pow(2) - z_log_var.exp())\n",
    "    \n",
    "def recon_loss(inputs, outputs):\n",
    "    return F.mse_loss(inputs, outputs, reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning_extensions import BaseModule\n",
    "\n",
    "class VAEModule(BaseModule):\n",
    "    def __init__(self):\n",
    "        model = VAE(x_dim=784, h_dim1=512, h_dim2=256, z_dim=2)\n",
    "        super().__init__(model)\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        return self.model(x, y)\n",
    "\n",
    "    def step(self, batch, batch_idx, mode = 'train'):\n",
    "        x, y = batch\n",
    "        x_hat = self(x, y)\n",
    "        loss = self.model.loss(batch, x_hat)\n",
    "        self.log_dict({f\"{mode}_{key}\": val.item() for key, val in loss.items()}, sync_dist=True, prog_bar=True)\n",
    "        return loss['loss']\n",
    "\n",
    "from softadapt import SoftAdapt, NormalizedSoftAdapt, LossWeightedSoftAdapt\n",
    "class VAEModuleSoftAdapt(BaseModule):\n",
    "    def __init__(self):\n",
    "        model = VAE(x_dim=784, h_dim1=512, h_dim2=256, z_dim=2)\n",
    "        self.softadapt_object = LossWeightedSoftAdapt(beta=0.001)\n",
    "        self.reconstruction_losses = []\n",
    "        self.kl_losses = []\n",
    "        self.adapt_weights = torch.tensor([1,1])\n",
    "        super().__init__(model)\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        return self.model(x, y)\n",
    "\n",
    "    def step(self, batch, batch_idx, mode = 'train'):\n",
    "        x, y = batch\n",
    "        x_hat = self(x, y)\n",
    "        loss = self.model.loss(batch, x_hat)\n",
    "\n",
    "        self.log_dict({f\"{mode}_{key}\": val.item() for key, val in loss.items()}, prog_bar=True)\n",
    "        \n",
    "        recon = loss['recon_loss_0']\n",
    "        kl = loss['kl_loss']\n",
    "\n",
    "        if mode == 'train':\n",
    "            self.reconstruction_losses.append(recon)\n",
    "            self.kl_losses.append(kl)\n",
    "\n",
    "        if len(self.reconstruction_losses) > 100 and mode == 'train':\n",
    "            first = torch.tensor(self.reconstruction_losses, dtype=torch.float64)\n",
    "            second = torch.tensor(self.kl_losses, dtype=torch.float64)\n",
    "\n",
    "            self.adapt_weights = self.softadapt_object.get_component_weights(first, second, verbose=False)\n",
    "\n",
    "            self.reconstruction_losses = []\n",
    "            self.kl_losses = []\n",
    "\n",
    "        return self.adapt_weights[0]  * recon + self.adapt_weights[1] * kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning_extensions import ExtendedTrainer\n",
    "\n",
    "model = VAEModule()\n",
    "model_name = \"VAE-simple\"\n",
    "trainer = ExtendedTrainer(project_name=\"MTVAEs_SoftAdapt\", max_epochs=30, model_name=model_name)\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning_extensions import ExtendedTrainer\n",
    "\n",
    "model = VAEModuleSoftAdapt()\n",
    "model_name = \"VAE-softadapt\"\n",
    "trainer = ExtendedTrainer(project_name=\"MTVAEs_SoftAdapt\", max_epochs=30, model_name=model_name)\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:  tensor([1, 1])\n",
      "Epoch: 1, Loss: 4163.302734375, BCE Loss: 3809.1845703125, KLD Loss: 354.11761474609375\n",
      "Weights:  tensor([1, 1])\n",
      "Epoch: 2, Loss: 3935.875, BCE Loss: 3529.89306640625, KLD Loss: 405.9815673828125\n",
      "Weights:  tensor([1, 1])\n",
      "Epoch: 3, Loss: 3798.40869140625, BCE Loss: 3353.83349609375, KLD Loss: 444.57537841796875\n",
      "Weights:  tensor([1, 1])\n",
      "Epoch: 4, Loss: 3714.271484375, BCE Loss: 3254.0146484375, KLD Loss: 460.25726318359375\n",
      "Weights:  tensor([1, 1])\n",
      "Epoch: 5, Loss: 3666.865966796875, BCE Loss: 3198.347900390625, KLD Loss: 468.5180358886719\n",
      "Weights:  tensor([1, 1])\n",
      "Epoch: 6, Loss: 3642.686767578125, BCE Loss: 3136.531982421875, KLD Loss: 506.1553955078125\n",
      "Weights:  tensor([1, 1])\n",
      "Epoch: 7, Loss: 3600.828125, BCE Loss: 3099.433837890625, KLD Loss: 501.39385986328125\n",
      "Weights:  tensor([1, 1])\n",
      "Epoch: 8, Loss: 3579.992431640625, BCE Loss: 3091.715576171875, KLD Loss: 488.2769775390625\n",
      "Weights:  tensor([1, 1])\n",
      "Epoch: 9, Loss: 3547.362548828125, BCE Loss: 3048.224609375, KLD Loss: 499.1383972167969\n",
      "Weights:  tensor([1, 1])\n",
      "Epoch: 10, Loss: 3533.648193359375, BCE Loss: 3028.97998046875, KLD Loss: 504.6676940917969\n",
      "Weights:  tensor([1, 1])\n",
      "Epoch: 11, Loss: 3529.905029296875, BCE Loss: 3004.240966796875, KLD Loss: 525.6644897460938\n",
      "Weights:  tensor([1, 1])\n",
      "Epoch: 12, Loss: 3504.248779296875, BCE Loss: 2979.9140625, KLD Loss: 524.33447265625\n",
      "Weights:  tensor([1, 1])\n",
      "Epoch: 13, Loss: 3522.5126953125, BCE Loss: 3015.14501953125, KLD Loss: 507.36749267578125\n",
      "Weights:  tensor([1, 1])\n",
      "Epoch: 14, Loss: 3482.19677734375, BCE Loss: 2949.850830078125, KLD Loss: 532.34619140625\n",
      "Weights:  tensor([1, 1])\n",
      "Epoch: 15, Loss: 3470.646484375, BCE Loss: 2943.250244140625, KLD Loss: 527.3965454101562\n",
      "Weights:  tensor([1, 1])\n",
      "Epoch: 16, Loss: 3477.27197265625, BCE Loss: 2960.258056640625, KLD Loss: 517.0135498046875\n",
      "Weights:  tensor([1, 1])\n",
      "Epoch: 17, Loss: 3479.06689453125, BCE Loss: 2959.00634765625, KLD Loss: 520.060791015625\n",
      "Weights:  tensor([1, 1])\n",
      "Epoch: 18, Loss: 3453.202880859375, BCE Loss: 2924.22021484375, KLD Loss: 528.982666015625\n",
      "Weights:  tensor([1, 1])\n",
      "Epoch: 19, Loss: 3464.49365234375, BCE Loss: 2942.086181640625, KLD Loss: 522.4075927734375\n",
      "Weights:  tensor([1, 1])\n",
      "Epoch: 20, Loss: 3452.349609375, BCE Loss: 2920.11279296875, KLD Loss: 532.2362060546875\n",
      "Weights:  tensor([1, 1])\n",
      "Epoch: 21, Loss: 3441.99365234375, BCE Loss: 2903.3955078125, KLD Loss: 538.5984497070312\n",
      "Weights:  tensor([1, 1])\n",
      "Epoch: 22, Loss: 3455.057861328125, BCE Loss: 2928.10791015625, KLD Loss: 526.9500122070312\n",
      "Weights:  tensor([1, 1])\n",
      "Epoch: 23, Loss: 3436.600830078125, BCE Loss: 2907.52685546875, KLD Loss: 529.0741577148438\n",
      "Weights:  tensor([1, 1])\n",
      "Epoch: 24, Loss: 3435.95068359375, BCE Loss: 2909.326171875, KLD Loss: 526.6243286132812\n",
      "Weights:  tensor([1, 1])\n",
      "Epoch: 25, Loss: 3418.5654296875, BCE Loss: 2869.67431640625, KLD Loss: 548.8912963867188\n",
      "Weights:  tensor([1, 1])\n",
      "Epoch: 26, Loss: 3424.207275390625, BCE Loss: 2879.449951171875, KLD Loss: 544.75732421875\n",
      "Weights:  tensor([1, 1])\n",
      "Epoch: 27, Loss: 3421.590576171875, BCE Loss: 2880.021240234375, KLD Loss: 541.5694580078125\n",
      "Weights:  tensor([1, 1])\n",
      "Epoch: 28, Loss: 3415.89404296875, BCE Loss: 2865.777099609375, KLD Loss: 550.116943359375\n",
      "Weights:  tensor([1, 1])\n",
      "Epoch: 29, Loss: 3427.651611328125, BCE Loss: 2881.3056640625, KLD Loss: 546.34619140625\n"
     ]
    }
   ],
   "source": [
    "model = VAE(x_dim=784, h_dim1=512, h_dim2=256, z_dim=2)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "for current_epoch in range(1, 30):\n",
    "    for x, y in mnist_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        x_recon, mean, log_var = model(x, y)\n",
    "        loss = model.loss((x, y), (x_recon, mean, log_var))\n",
    "        loss['loss'].backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validate\n",
    "    with torch.no_grad():\n",
    "        losses = []\n",
    "        bce_losses = []\n",
    "        kld_losses = []\n",
    "\n",
    "        for x, y in val_dataloader:\n",
    "            x_recon, mean, log_var = model(x, y)\n",
    "            loss = model.loss((x, y), (x_recon, mean, log_var))\n",
    "            losses.append(loss['loss'])\n",
    "            bce_losses.append(loss['BCE_loss'])\n",
    "            kld_losses.append(loss['KLD_loss'])\n",
    "        print(\"Weights: \", torch.tensor([1,1]))\n",
    "        print(\"Epoch: {}, Loss: {}, BCE Loss: {}, KLD Loss: {}\".format(current_epoch, torch.mean(torch.tensor(losses)), torch.mean(torch.tensor(bce_losses)), torch.mean(torch.tensor(kld_losses))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train example with softadapt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33medvardsz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Home/siv34/edzak2974/projects/MastersThesis/src/wandb/run-20231212_083646-adntejzu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/edvardsz/MTVAEs_SoftAdapt/runs/adntejzu' target=\"_blank\">VAE-softadapt-custom</a></strong> to <a href='https://wandb.ai/edvardsz/MTVAEs_SoftAdapt' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/edvardsz/MTVAEs_SoftAdapt' target=\"_blank\">https://wandb.ai/edvardsz/MTVAEs_SoftAdapt</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/edvardsz/MTVAEs_SoftAdapt/runs/adntejzu' target=\"_blank\">https://wandb.ai/edvardsz/MTVAEs_SoftAdapt/runs/adntejzu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:  tensor([0.8530, 0.1470], dtype=torch.float64)\n",
      "Epoch: 1, Loss: 4242.599609375, BCE Loss: 3583.261962890625, KLD Loss: 659.33740234375\n",
      "Weights:  tensor([0.8725, 0.1275], dtype=torch.float64)\n",
      "Epoch: 2, Loss: 4024.90625, BCE Loss: 3352.579345703125, KLD Loss: 672.3267211914062\n",
      "Weights:  tensor([0.8157, 0.1843], dtype=torch.float64)\n",
      "Epoch: 3, Loss: 3856.71240234375, BCE Loss: 3211.237548828125, KLD Loss: 645.4752197265625\n",
      "Weights:  tensor([0.8474, 0.1526], dtype=torch.float64)\n",
      "Epoch: 4, Loss: 3793.824951171875, BCE Loss: 3117.480224609375, KLD Loss: 676.3447875976562\n",
      "Weights:  tensor([0.8203, 0.1797], dtype=torch.float64)\n",
      "Epoch: 5, Loss: 3738.108154296875, BCE Loss: 3070.41943359375, KLD Loss: 667.6888427734375\n",
      "Weights:  tensor([0.8201, 0.1799], dtype=torch.float64)\n",
      "Epoch: 6, Loss: 3698.8583984375, BCE Loss: 3006.57373046875, KLD Loss: 692.28466796875\n",
      "Weights:  tensor([0.8181, 0.1819], dtype=torch.float64)\n",
      "Epoch: 7, Loss: 3665.492919921875, BCE Loss: 2979.7001953125, KLD Loss: 685.7924194335938\n",
      "Weights:  tensor([0.8246, 0.1754], dtype=torch.float64)\n",
      "Epoch: 8, Loss: 3650.703857421875, BCE Loss: 2961.578369140625, KLD Loss: 689.1253051757812\n",
      "Weights:  tensor([0.8186, 0.1814], dtype=torch.float64)\n",
      "Epoch: 9, Loss: 3621.0068359375, BCE Loss: 2928.88720703125, KLD Loss: 692.1195068359375\n",
      "Weights:  tensor([0.7835, 0.2165], dtype=torch.float64)\n",
      "Epoch: 10, Loss: 3597.002197265625, BCE Loss: 2934.11474609375, KLD Loss: 662.8875732421875\n",
      "Weights:  tensor([0.8040, 0.1960], dtype=torch.float64)\n",
      "Epoch: 11, Loss: 3572.397216796875, BCE Loss: 2896.726318359375, KLD Loss: 675.670654296875\n",
      "Weights:  tensor([0.8145, 0.1855], dtype=torch.float64)\n",
      "Epoch: 12, Loss: 3587.1962890625, BCE Loss: 2887.659912109375, KLD Loss: 699.5361938476562\n",
      "Weights:  tensor([0.7972, 0.2028], dtype=torch.float64)\n",
      "Epoch: 13, Loss: 3556.96728515625, BCE Loss: 2873.1259765625, KLD Loss: 683.8407592773438\n",
      "Weights:  tensor([0.7820, 0.2180], dtype=torch.float64)\n",
      "Epoch: 14, Loss: 3549.353515625, BCE Loss: 2874.038818359375, KLD Loss: 675.3150024414062\n",
      "Weights:  tensor([0.7801, 0.2199], dtype=torch.float64)\n",
      "Epoch: 15, Loss: 3525.5673828125, BCE Loss: 2835.0556640625, KLD Loss: 690.51171875\n",
      "Weights:  tensor([0.7992, 0.2008], dtype=torch.float64)\n",
      "Epoch: 16, Loss: 3533.847412109375, BCE Loss: 2823.84716796875, KLD Loss: 710.000244140625\n",
      "Weights:  tensor([0.7812, 0.2188], dtype=torch.float64)\n",
      "Epoch: 17, Loss: 3521.617431640625, BCE Loss: 2817.384765625, KLD Loss: 704.2327270507812\n",
      "Weights:  tensor([0.7895, 0.2105], dtype=torch.float64)\n",
      "Epoch: 18, Loss: 3520.210693359375, BCE Loss: 2818.471923828125, KLD Loss: 701.7390747070312\n",
      "Weights:  tensor([0.7894, 0.2106], dtype=torch.float64)\n",
      "Epoch: 19, Loss: 3521.212890625, BCE Loss: 2821.3212890625, KLD Loss: 699.8917236328125\n",
      "Weights:  tensor([0.7952, 0.2048], dtype=torch.float64)\n",
      "Epoch: 20, Loss: 3501.944580078125, BCE Loss: 2800.379150390625, KLD Loss: 701.5654907226562\n",
      "Weights:  tensor([0.7763, 0.2237], dtype=torch.float64)\n",
      "Epoch: 21, Loss: 3489.260009765625, BCE Loss: 2794.221923828125, KLD Loss: 695.0374755859375\n",
      "Weights:  tensor([0.7750, 0.2250], dtype=torch.float64)\n",
      "Epoch: 22, Loss: 3486.305908203125, BCE Loss: 2789.906494140625, KLD Loss: 696.3992919921875\n",
      "Weights:  tensor([0.7881, 0.2119], dtype=torch.float64)\n",
      "Epoch: 23, Loss: 3491.710205078125, BCE Loss: 2784.127197265625, KLD Loss: 707.5829467773438\n",
      "Weights:  tensor([0.7862, 0.2138], dtype=torch.float64)\n",
      "Epoch: 24, Loss: 3489.849365234375, BCE Loss: 2772.378662109375, KLD Loss: 717.4701538085938\n",
      "Weights:  tensor([0.7697, 0.2303], dtype=torch.float64)\n",
      "Epoch: 25, Loss: 3466.0341796875, BCE Loss: 2763.61865234375, KLD Loss: 702.4157104492188\n",
      "Weights:  tensor([0.7797, 0.2203], dtype=torch.float64)\n",
      "Epoch: 26, Loss: 3468.607421875, BCE Loss: 2763.797607421875, KLD Loss: 704.8099365234375\n",
      "Weights:  tensor([0.7737, 0.2263], dtype=torch.float64)\n",
      "Epoch: 27, Loss: 3472.29541015625, BCE Loss: 2767.0810546875, KLD Loss: 705.2144775390625\n",
      "Weights:  tensor([0.8155, 0.1845], dtype=torch.float64)\n",
      "Epoch: 28, Loss: 3489.027099609375, BCE Loss: 2754.9228515625, KLD Loss: 734.1045532226562\n",
      "Weights:  tensor([0.8182, 0.1818], dtype=torch.float64)\n",
      "Epoch: 29, Loss: 3503.2626953125, BCE Loss: 2763.833740234375, KLD Loss: 739.4290771484375\n"
     ]
    }
   ],
   "source": [
    "from softadapt import SoftAdapt, NormalizedSoftAdapt, LossWeightedSoftAdapt\n",
    "import wandb\n",
    "\n",
    "model = VAE(x_dim=784, h_dim1=512, h_dim2=256, z_dim=2)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "# Change 1: Create a SoftAdapt object (with your desired variant)\n",
    "softadapt_object = LossWeightedSoftAdapt(beta=0.001)\n",
    "\n",
    "# Change 2: Define how often SoftAdapt calculate weights for the loss components\n",
    "epochs_to_make_updates = 5\n",
    "\n",
    "values_of_component_1 = []\n",
    "values_of_component_2 = []\n",
    "# Initializing adaptive weights to all ones.\n",
    "adapt_weights = torch.tensor([1,1])\n",
    "\n",
    "limit = 101\n",
    "\n",
    "count = 0\n",
    "\n",
    "wandb.init(project=\"MTVAEs_SoftAdapt\", name=\"VAE-softadapt-custom\")\n",
    "for current_epoch in range(1, 30):\n",
    "    for x, y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        count += 1\n",
    "        x_recon, mean, log_var = model(x, y)\n",
    "        loss = model.loss((x, y), (x_recon, mean, log_var))\n",
    "\n",
    "        bce_loss = loss['recon_loss_0']\n",
    "        kld = loss['kl_loss']\n",
    "\n",
    "        values_of_component_1.append(bce_loss)\n",
    "        values_of_component_2.append(kld)\n",
    "\n",
    "        if (current_epoch % epochs_to_make_updates == 0 and current_epoch > 1 and count >= limit) or count >= limit:\n",
    "            # Change 3: Update weights of components\n",
    "            count = 0\n",
    "            # print(\"Adaptive weights: \", adapt_weights)\n",
    "            # print(\"epoch\")\n",
    "            # print(current_epoch)\n",
    "            first = torch.tensor(values_of_component_1, dtype=torch.float64)\n",
    "            second = torch.tensor(values_of_component_2, dtype=torch.float64)\n",
    "            # print(first)\n",
    "            # print(second)\n",
    "            # print(first.dtype)\n",
    "            # print(second.dtype)\n",
    "            # print(first.shape)\n",
    "            # print(second.shape)\n",
    "            adapt_weights = softadapt_object.get_component_weights(first, second,verbose=False)\n",
    "            #print(\"WORKS\")\n",
    "                                           \n",
    "        \n",
    "            # Resetting the lists to start fresh (this part is optional)\n",
    "            values_of_component_1 = []\n",
    "            values_of_component_2 = []\n",
    "\n",
    "        loss = adapt_weights[0] * bce_loss + adapt_weights[1] * kld\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #wandb.log({\"train_loss\": loss, \"train_recon_loss_0\": bce_loss, \"train_kl_loss\": kld, \"epoch\": current_epoch})\n",
    "\n",
    "    # Validate\n",
    "    with torch.no_grad():\n",
    "        losses = []\n",
    "        bce_losses = []\n",
    "        kld_losses = []\n",
    "\n",
    "        for x, y in val_loader:\n",
    "            x_recon, mean, log_var = model(x, y)\n",
    "            loss = model.loss((x, y), (x_recon, mean, log_var))\n",
    "            losses.append(loss['loss'])\n",
    "            bce_losses.append(loss['recon_loss_0'])\n",
    "            kld_losses.append(loss['kl_loss'])\n",
    "        print(\"Weights: \", adapt_weights)\n",
    "        print(\"Epoch: {}, Loss: {}, BCE Loss: {}, KLD Loss: {}\".format(current_epoch, torch.mean(torch.tensor(losses)), torch.mean(torch.tensor(bce_losses)), torch.mean(torch.tensor(kld_losses))))\n",
    "        wandb.log({\"val_loss\": torch.mean(torch.tensor(losses)), \"val_recon_loss_0\": torch.mean(torch.tensor(bce_losses)), \"val_kl_loss\": torch.mean(torch.tensor(kld_losses))})\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
