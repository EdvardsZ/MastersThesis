\chapter{Methods}

This chapter will outline the methods how SCVAEs and non-conditioned VAEs are
integrated using multitask learning in this thesis, which will be explored in
the context of images. The chapter will be divided in three sections. The first
section will describe the conditioning strategies, which will be used to
condition the VAEs. In the following section, I will describe the method of
merging SCVAEs with non-conditioned VAEs using two decoders, where one is
conditioned, and the other is not. This method will be referred to as
\method{1}. In the following section, I describe another method of merging
SCVAEs with non-conditioned VAEs by utilizing the same encoder and decoder for
both models by employing novel training strategies, which will be referred to
as \method{2}. Both methods will be applied to both Gaussian VAEs and VQ-VAEs.

\section{Conditioning information}

In this thesis, I will obtain the conditioning information $m$ from the input
image $x$ by sampling pixels some pixels from the input image $x$. In this
process first the first step is to obtain a mask which will be used to sample
the pixels from the input image $x$. The mask will be a binary matrix of the
same size as the input image $x$, where a value of 1 represents the sampled
pixels and a value of 0 represents the pixels that are not sampled. The
decision how many pixels to sample and which pixels to sample will be described
in the following sections for each method.

After the mask is obtained, the mask is applied to the input image $x$ to
obtain the masked image, which is then used to obtain the conditioning
information $m$ by concatenating the mask with the masked image, which can be
seen in Figure~\ref{ConditioningFigure}.

In both proposed methods, the conditioning information $m$ will be incorporated
into decoder by first flattening it and then concatenating it with the input of the decoder and then using a fully connected layer before passing it through the transposed convolutional layers of the decoder.

\begin{figure}
    \centering
    \input{figures/conditioning.tex}
    \caption[The illustration of the process of obtaining the conditioning information $m$ from the input image $x$ and the mask.]%
    {
        The illustration of the process of obtaining the conditioning information $m$ from the input image $x$ and the mask. The process to obtain the conditioning information $m$ consists of two steps: the first step is to obtain the masked image from the input image $x$ and the mask, and the second step is to add the mask to the masked image to obtain the conditioning information $m$. The conditioning information $m$ is then used to condition the decoder.
    }\label{ConditioningFigure}
\end{figure}

\section{\method{1}}

In the first method, VAEs framework is expanded with a second decoder
$p_\xi(x|z,m)$, which is conditioned on an additional property $m$ of the input
data. This approach involves utilizing two decoders within the VAEs framework:
one for reconstructing the input data solely based on the latent variable $z$,
and the other for reconstructing the input data based on both the latent
variable $z$ and the additional conditioning information $m$.

\subsection{Conditioning strategy}

In this method, the conditioning information $m$ is acquired by sampling
constant number of pixels from the input data. To sample the pixels from the
input image $x$, I will use a pixel sampling operation, which will be described
in the following section.

\subsubsection{Pixel Sampling operation}

I will explore two pixel sampling types for this method,
which can be seen in Figure~\ref{SamplingFigure} and are described as follows:

\begin{enumerate}
    \item \textbf{Exact same sampling:} In this sampling type, the conditioning information $m$ is sampled from the input image $x$ by sampling the exact same sparse pixels from the input image $x$. In this work, the pixels that will be sampled from the input image will be a sparse grid of pixels.
    \item \textbf{Uniform random sampling:} In this sampling type, the conditioning information $m$ is sampled from the input image $x$ by sampling exact number of pixels from the input image $x$ uniformly at random.
\end{enumerate}

The sampling process will be done every time the input image $x$ is passed through the model. This means that in the case of the uniform random sampling, the conditioning information $m$ will be different for each time the image is passed through the model. This is done to ensure that the model learns to generalize and handle various cases.

\subsection{Application to Gaussian VAEs}

In Gaussian VAEs, the integration of a second conditioned decoder
$p_\xi(x|z,m)$ follows a similar approach as outlined in the general method
description. However, there are specific adjustments and considerations that
need to be taken into account when applying this method to Gaussian VAEs.

The integration of the second conditioned decoder $p_\xi(x|z,m)$ into the
Gaussian VAEs framework involves flattening on concatenating the latent
variable $z$ and the conditioning information $m$ and passing it through a
fully connected layer before passing it through the transposed convolutional
layers of the second decoder. Although a new latent variable could have
been sampled for the second decoder, the same latent variable $z$ is used
instead of sampling a new one. This is done to ensure that the latent variable
$z$ is the same for both decoders and ensure that it is easier to compare the
reconstructions of the input data. The architecture of the Gaussian
VAEs framework with the second conditioned decoder is illustrated in
Figure~\ref{SCVAE2DFigure}

Although the training strategy could have been to train decoders by alternating between them, in this thesis, I will explore the training strategy where both decoders are trained simultaneously.

In Gaussian VAEs, the loss objective consists of two components: the
reconstruction loss and the KL divergence term. However, with the inclusion of
the second conditioned decoder, the loss objective is extended to include the
reconstruction loss of the second conditioned decoder. The overall loss
objective to be \textbf{minimized} becomes

\[ L = W_1 \frac{1}{D} \sum_{i=1}^{D} ||x_i - \hat{x}_{1_{i}} ||^2 + W_2 \frac{1}{D} \sum_{i=1}^{D} || x_i - \hat{x}_{2_{i}} ||^2 + \beta  \frac{1}{2} \sum_{i=1}^{Z} \biggl( -\log \sigma^2_\phi(x)_i - 1 + \mu^2_\phi(x)_i + \sigma^2_\phi(x)_i \biggr), \]

where $D$ is the number of pixels in the input image, $x_i$ is the $i$-th pixel
of the input image, $\hat{x}_1$ is the output of the first decoder, $\hat{x}_2$
is the output of the second decoder, $\beta$ is the KL divergence weight, Z is
the dimension of the latent space, $\mu_\phi(x)$ and $\sigma_\phi(x)$ are the
mean and the standard deviation of the Gaussian distribution produced by the
encoder, respectively. The resulting loss has also extra weight parameters $W_1$ and $W_2$ to balance and control the importance of reconstruction loss, which will be hyperparameters of the model.

During the training process, the encoder is trained to produce accurate mean
and standard deviation of the Gaussian distribution, and the decoders are
trained to produce accurate reconstructions of the input data. The KL
divergence term is used to regularize the latent space to be close to a
standard Gaussian distribution. The optimizer used to minimize the overall loss
objective is the AdamW optimizer~\cite{AdamW}.

As a result of the integration of the second conditioned decoder, the model has
the ability to reconstruct the input data based just on the latent variable $z$
and as well as the conditioning information $m$.
\begin{figure}[H]
    \centering
    \input{figures/scvae2d.tex}
    \caption[\method{1} applied to Gaussian VAEs.]%
    {
        \methodOne\ applied to Gaussian VAEs. The Gaussian VAEs framework is extended by adding a second conditioned decoder $p_\xi(x|z,m)$. The input $x$ is passed through the encoder with parameters $\phi$ producing the mean $\mu$ and the standard deviation $\sigma$ of the Gaussian distribution. The random variable $\epsilon$ is sampled from a standard Gaussian distribution and is used to sample $ z = \mu + \sigma \odot \epsilon$. The sampled $z$ is then used as input to both decoders. As a result, the loss function consists of three components: the MSE reconstruction loss of the first decoder, the MSE reconstruction loss of the second decoder and the KL divergence regularization loss.
    }\label{SCVAE2DFigure}
\end{figure}

\subsection{Application to VQ-VAEs}

The approach of integrating the second conditioned decoder $p_\xi(x|z,m)$ into
the VQ-VAEs framework is similar to the approach used for Gaussian VAEs.
However, there differences that need to be taken into account when applying
this method to VQ-VAEs.

One of the main differences is that the VQ-VAEs framework uses a discrete
latent space and the Vector Quantization which is described in \autoref{background:vqvae}. This means that the latent variable $z$ is a discrete variable which represents the indexes of the embedding table vectors. This means that first the corresponding embedding table vectors $z_q(x)$ must be computed for the latent variable $z$ before flattening and concatenating it with the conditioning information $m$ and then using a fully connected layer before the transposed convolutional layers of the second decoder. The architecture of the VQ-VAEs framework with the second conditioned decoder is illustrated in Figure~\ref{SCVQVAE2DFigure}.

The training strategy is the same as in Gaussian VAEs, where both decoders are trained simultaneously. This means that the loss objective must be extended to include the reconstruction loss of the second conditioned decoder. In VQ-VAEs, the loss objective consists of three components: the MSE
reconstruction loss and the commitment loss and the codebook loss. However,
with the inclusion of the second conditioned decoder, the loss objective is
extended to include the reconstruction loss of the second conditioned decoder.
The overall loss objective to be \textbf{minimized} becomes

\[ L = W_1 \frac{1}{D} \sum_{i=1}^{D} ||x_i - \hat{x}_{1_{i}} ||^2 +  W_2 \frac{1}{D} \sum_{i=1}^{D} || x_i - \hat{x}_{2_{i}} ||^2 + \frac{1}{Z} \sum_{i=1}^{Z} \biggl( || sg(z_e(x)_i) - e_{k_i} ||^2 + \beta || z_q(x)_i - sg(e_{k{_i}}) ||^2 \biggr) , \]

% TODO explain the weights W1 and W2

where $D$ is the number of pixels in the input image, $x_i$ is the $i$-th pixel
of the input image, $\hat{x}_1$ is the output of the first decoder, $\hat{x}_2$
is the output of the second decoder, $Z$ is the number of latent space vectors,
$z_e(x)$ is the output of the encoder, $z_q(x)$ is the mapping output after
Vector Quantization, $e_k$ is the $k$-th embedding table vector, $\beta$ is the
commitment loss weight, $sg$ is the stop gradient operation, which was
previously defined in the background \autoref{background:vqvae}.

After the first stage of the training, the model has the ability to reconstruct
the input data based just on the latent variable $z$ and as well as the
conditioning information $m$. To generate the latent variable $z$ there must be
trained a separate autoregressive model, which will be used to generate the
latent variable $z$.

\begin{figure}[H]
    \centering
    \input{figures/scvqvae2d.tex}
    \caption[\method{1} applied to VQ-VAEs.]%
    {
        \method{1} applied to VQ-VAEs. The VQ-VAEs framework is extended by adding a second conditioned decoder. Instead of using a fully connected layer to merge the latent variable $z$ and the conditioning information $m$, the corresponding embedding table vectors $z_q(x)$ must be computed for the latent variable $z$ before merging it with the conditioning information $m$. As a result of adding the second conditioned decoder, the loss function requires the addition of the MSE reconstruction loss of the second decoder.
    }\label{SCVQVAE2DFigure}
\end{figure}

\section{\method{2}}

In the \method{2}, the idea is to employ a single decoder within the VAE architecture that is capable of reconstructing the input data under variable conditioning. The variable conditioning means that the conditioning information $m$ can be a variable amount of information or just an empty mask. This method differs from the \method{1} in that it uses a single decoder for both tasks and dynamically adjusts its behavior based on the amount of information present in the variable $m$.

This method utilizes a single decoder that dynamically adjusts its behavior
based on the amount of information present in the variable $m$. When the
conditioning information is available, the decoder incorporates it into the
reconstruction process and takes advantage of it to get the best
reconstruction. Otherwise, it operates solely based on the latent variable $z$.

To achieve this, in this method I will use different conditioning strategy, which will be described in the following subsection.

\subsection{Conditioning strategy}

Similar to the previous method, the conditioning information $m$ is acquired by
sampling pixels from the input image $x$. However, in this method the process of sampling the conditioning information $m$ is different in that the conditioning information $m$ is sampled by selecting a variable number of pixels from the input image $x$. This is done to ensure that the decoder of the model learns to handle various cases where there is variable conditioning information.

To achieve this, I will implement a two-step sampling process:

\begin{enumerate}
    \item \textbf{Sampling the number of pixels:} In this step, the number of pixels to be sampled from the input image $x$ is sampled from a power law distribution. The power law distribution is scaled to the size of the input image $x$ and is used to sample the number of pixels to be sampled from the input image $x$.
    \item \textbf{Sampling the pixels:} In this step, the conditioning information $m$ is sampled from the input image $x$ by sampling the number of pixels sampled in the previous step from the input image: uniformly at random or from a Gaussian distribution. Both of these sampling types can be seen in Figure~\ref{SamplingFigure}.
\end{enumerate}

The sampling two-step process will be done every time the input image $x$ is passed through the model. This means that the conditioning information $m$ will be different for each time the image is passed through the model. This is done to ensure that the model learns to generalize and handle various cases.

During training, the number of pixels to be sampled from the input image $x$ varies every time the input image $x$ is passed through the model and is sampled from a power law distribution.
The power law distribution is chosen because it can have finite range and scalability, which makes it suitable for sampling the number of pixels from the input image. The exponent of the power law distribution will be chosen to be high so that the decoder can learn to handle also the cases where the conditioning information is not available. The exponent will be a hyperparameter of the model.


\subsection{Application to Gaussian VAEs}

In Gaussian VAEs, applying the second method involves modifying the decoder to
be capable of reconstructing the input data under variable conditioning. The
modified decoder $p_\xi(x|z,m)$ is capable of reconstructing the input data
based on the latent variable $z$ and the conditioning information $m$ or just
the latent variable $z$.

This is achieved by using a fully connected layer to merge the latent variable
$z$ and the conditioning information $m$ before passing it through the
transposed convolutional layers. The architecture of the Gaussian VAEs
framework with a single decoder capable of variable conditioning is illustrated
in Figure~\ref{SCVAE1DFigure}.

\begin{figure}[H]
    \centering
    \input{figures/scvae1d.tex}
    \caption[\method{2} applied to Gaussian VAEs.]%
    {
        \methodTwo\ applied to Gaussian VAEs. The Gaussian VAEs framework is modified by allowing the decoder to be conditioned on a variable amount of information and to dynamically adjust its behavior based on the amount of information present in the variable $m$. The input $x$ is passed through the encoder with parameters $\phi$ producing the mean $\mu$ and the standard deviation $\sigma$ of the Gaussian distribution. The random variable $\epsilon$ is sampled from a standard Gaussian distribution and is used to sample $ z = \mu + \sigma \odot \epsilon$. The sampled $z$ is then used as input to the decoder as well as the extra conditioning information $m$. With this approach there is no need for a second decoder, as the single decoder is capable to reconstruct the data based on the latent variable $z$ and the conditioning information $m$ or just the latent variable $z$.
    }\label{SCVAE1DFigure}
\end{figure}

\subsection{Application to VQ-VAEs}

In VQVAEs, same as in Gaussian VAEs, the second method involves modifying the
decoder to be capable to receive variable conditioning information. Unlike
Gaussian VAEs, the VQ-VAEs use Vector Quantization to discretize the continuous
latent space. Because of this, the latent variable $z$ can not be directly
merged with the conditioning information $m$ using a fully connected layer.
Instead, the corresponding embedding table vectors $z_q(x)$ must be computed
for the latent variable $z$ before merging it with the conditioning information
$m$. The architecture of the VQ-VAEs framework with a single decoder capable of
variable conditioning is illustrated in Figure~\ref{SCVQVAE1DFigure}.

\begin{figure}[H]
    \centering
    \input{figures/scvqvae1d.tex}
    \caption[\method{2} applied to VQ-VAEs.]%
    {
        \methodTwo\ applied to VQ-VAEs. The VQ-VAEs framework is modified by allowing the decoder to be conditioned on a variable amount of information and to dynamically adjust its behavior based on the amount of information present in the variable $m$. The input $x$ is passed through the encoder producing the output $z_e(x)$. The output $z_e(x)$ is then used as input to the autoregressive model to generate the latent variable $z$. The latent variable $z$ is then used as input to the decoder as well as the extra conditioning information $m$. With this approach there is no need for a second decoder, as the single decoder is capable to reconstruct the data based on the latent variable $z$ and the conditioning information $m$ or just the latent variable $z$.
    }\label{SCVQVAE1DFigure}
\end{figure}

\begin{figure}
    \centering
    \input{figures/sampling.tex}
    \caption[Table of pixel sampling types for conditioning.]%
    {
        Table of pixel sampling types for conditioning. The table has 3 rows each representing a different sampling type. The first row represents the exact same sampling type, the second row represents the uniform random sampling type and the third row represents the Gaussian sampling type where the pixels are more likely to be sampled from the center of the image. The first column represents the original image, the second column represents the mask and the third column represents the result of the sampling operation.
    }\label{SamplingFigure}
\end{figure}

