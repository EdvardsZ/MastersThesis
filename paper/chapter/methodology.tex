\chapter{Methods}

This chapter will outline the methods how SCVAEs and non-conditioned VAEs are
integrated using multitask learning in this thesis. Initially, I describe the
method of merging SCVAEs with non-conditioned VAEs by expanding the SCVAEs
framework with a second decoder. In the following section, I describe another method of
merging SCVAEs with non-conditioned VAEs by utilizing the same encoder and
decoder for both models by employing novel training strategies. Both methods will be applied to both Gaussian VAEs and VQ-VAEs.


\section{\method{1}}

In the first method, VAEs framework is expanded with a second decoder
$p_\xi(x|z,m)$, which is conditioned on an additional property $m$ of the input
data. This approach involves utilizing two decoders within the VAEs framework:
one for reconstructing the input data solely based on the latent variable $z$,
and the other for reconstructing the input data based on both the latent
variable $z$ and the additional conditioning information $m$.

\subsection{Conditioning information}

In this method, the conditioning information $m$ is acquired by sampling
constant number of pixels from the input data. To sample the pixels from the
input image $x$, I will use a pixel sampling operation, which will be
described in the following section.

\subsubsection{Pixel Sampling operation}

To acquire the conditioning information $m$ from the input image $x$, I will
use sampling operation. I will explore two sampling types for this method,
which can be seen in Figure~\ref{SamplingFigure} and are described as follows:

\begin{enumerate}
    \item \textbf{Exact same sampling:} In this sampling type, the conditioning information $m$ is sampled from the input image $x$ by sampling the exact same sparse pixels from the input image $x$. In this work, the pixels that will be sampled from the input image will be a sparse grid of pixels.
    \item \textbf{Uniform random sampling:} In this sampling type, the conditioning information $m$ is sampled from the input image $x$ by sampling exact number of pixels from the input image $x$ uniformly at random.
\end{enumerate}

\subsection{Application to Gaussian VAEs}

In Gaussian VAEs, the integration of a second conditioned decoder
$p_\xi(x|z,m)$ follows a similar approach as outlined in the general method
description. However, there are specific adjustments and considerations that
need to be taken into account when applying this method to Gaussian VAEs.

The integration of the second conditioned decoder $p_\xi(x|z,m)$ into the
Gaussian VAEs framework involves using a fully connected layer to merge the
latent variable $z$ and the conditioning information $m$ before passing it
through the transposed convolutional layers. The architecture of the Gaussian
VAEs framework with the second conditioned decoder is illustrated in
Figure~\ref{SCVAE2DFigure}

In Gaussian VAEs, the loss objective consists of two components: the
reconstruction loss and the KL divergence term. However, with the inclusion of
the second conditioned decoder, the loss objective is extended to include the
reconstruction loss of the second conditioned decoder. The overall loss
objective to be \textbf{minimized} becomes

\[ L = \frac{1}{D} \sum_{i=1}^{D} ||x_i - \hat{x}_{1_{i}} ||^2 + \frac{1}{D} \sum_{i=1}^{D} || x_i - \hat{x}_{2_{i}} ||^2 + \beta  \frac{1}{2} \sum_{i=1}^{Z} \biggl( -\log \sigma^2_\phi(x)_i - 1 + \mu^2_\phi(x)_i + \sigma^2_\phi(x)_i \biggr), \]

where $D$ is the number of pixels in the input image, $x_i$ is the $i$-th pixel
of the input image, $\hat{x}_1$ is the output of the first decoder, $\hat{x}_2$
is the output of the second decoder, $\beta$ is the KL divergence weight, Z is the dimension of the latent space,
$\mu_\phi(x)$ and $\sigma_\phi(x)$ are the mean and the standard deviation of
the Gaussian distribution produced by the encoder, respectively.

During the training process, the encoder is trained to produce accurate mean
and standard deviation of the Gaussian distribution, and the decoders are
trained to produce accurate reconstructions of the input data. The KL
divergence term is used to regularize the latent space to be close to a
standard Gaussian distribution. The optimizer used to minimize the overall loss
objective is the AdamW optimizer~\cite{AdamW}.

As a result of the integration of the second conditioned decoder, the model has
the ability to reconstruct the input data based just on the latent variable $z$
and as well as the conditioning information $m$.
\begin{figure}[H]
    \centering
    \input{figures/scvae2d.tex}
    \caption[\method{1} applied to Gaussian VAEs.]%
    {
        \methodOne\ applied to Gaussian VAEs. The Gaussian VAEs framework is extended by adding a second conditioned decoder $p_\xi(x|z,m)$. The input $x$ is passed through the encoder with parameters $\phi$ producing the mean $\mu$ and the standard deviation $\sigma$ of the Gaussian distribution. The random variable $\epsilon$ is sampled from a standard Gaussian distribution and is used to sample $ z = \mu + \sigma \odot \epsilon$. The sampled $z$ is then used as input to both decoders. As a result, the loss function consists of three components: the MSE reconstruction loss of the first decoder, the MSE reconstruction loss of the second decoder and the KL divergence regularization loss.
    }\label{SCVAE2DFigure}
\end{figure}

\subsection{Application to VQ-VAEs}

The approach of integrating the second conditioned decoder $p_\xi(x|z,m)$ into
the VQ-VAEs framework is similar to the approach used for Gaussian VAEs.
However, there differences that need to be taken into account when applying
this method to VQ-VAEs.

One of the main differences is that the VQ-VAEs framework uses a discrete
latent space and the Vector Quantization. Because of this, the latent variable
$z$ can not be directly merged with the conditioning information $m$ using a
fully connected layer. Instead, the corresponding embedding table vectors
$z_q(x)$ must be computed for the latent variable $z$ before merging it with
the conditioning information $m$. The architecture of the VQ-VAEs framework
with the second conditioned decoder is illustrated in
Figure~\ref{SCVQVAE2DFigure}.

In VQ-VAEs, the loss objective consists of three components: the MSE
reconstruction loss and the commitment loss and the codebook loss. However,
with the inclusion of the second conditioned decoder, the loss objective is
extended to include the reconstruction loss of the second conditioned decoder.
The overall loss objective to be \textbf{minimized} becomes

\[ L = \frac{1}{D} \sum_{i=1}^{D} ||x_i - \hat{x}_{1_{i}} ||^2 + \frac{1}{D} \sum_{i=1}^{D} || x_i - \hat{x}_{2_{i}} ||^2 + \frac{1}{Z} \sum_{i=1}^{Z} \biggl( || sg(z_e(x)_i) - e_{k_i} ||^2 + \beta || z_q(x)_i - sg(e_{k{_i}}) ||^2 \biggr) , \]

where $D$ is the number of pixels in the input image, $x_i$ is the $i$-th pixel
of the input image, $\hat{x}_1$ is the output of the first decoder, $\hat{x}_2$
is the output of the second decoder, $Z$ is the number of latent space vectors,
 $z_e(x)$ is the output of the encoder,
$z_q(x)$ is the mapping output after Vector Quantization, $e_k$ is the $k$-th
embedding table vector, $\beta$ is the commitment loss weight, $sg$ is the stop
gradient operation, which was previously defined in the background \autoref{background:vqvae}.

After the first stage of the training, the model has the ability to reconstruct
the input data based just on the latent variable $z$ and as well as the
conditioning information $m$. To generate the latent variable $z$ there must be
trained a separate autoregressive model, which will be used to generate the
latent variable $z$.

\begin{figure}[H]
    \centering
    \input{figures/scvqvae2d.tex}
    \caption[\method{1} applied to VQ-VAEs.]%
    {
        \method{1} applied to VQ-VAEs. The VQ-VAEs framework is extended by adding a second conditioned decoder. Instead of using a fully connected layer to merge the latent variable $z$ and the conditioning information $m$, the corresponding embedding table vectors $z_q(x)$ must be computed for the latent variable $z$ before merging it with the conditioning information $m$. As a result of adding the second conditioned decoder, the loss function requires the addition of the MSE reconstruction loss of the second decoder.
    }\label{SCVQVAE2DFigure}
\end{figure}

\section{\method{2}}

In the second method, I use a single decoder within the VAE Architecture.
However, the use decoder is expanded to be capable of reconstructing the input
data under variable conditioning. The variable conditioning means that the
conditioning information $m$ can be a variable amount of information or just an
empty mask.

This method utilizes a single decoder that dynamically adjusts its behavior
based on the amount of information present in the variable $m$. When the
conditioning information is available, the decoder incorporates it into the
reconstruction process and takes advantage of it to get the best
reconstruction. Otherwise, it operates solely based on the latent variable $z$.

\subsection{Conditioning strategy}

Similar to the previous method, the conditioning information $m$ is acquired by sampling pixels from the input image $x$. However, in this method, the conditioning information $m$ is sampled by selecting a variable number of pixels from the input image $x$. The number of pixels to be sampled from the input image varies and is sampled from a power law distribution. The power law distribution is scaled to the size of the input image $x$ and is used to compute the number of pixels to be sampled from the input image $x$.

The conditioning information $m$ includes an additional mask, which indicates to the decoder which pixels are sampled from the input image $x$ and which pixels are not sampled. The mask is a binary matrix of the same size as the input image $x$, where a value of 1 represents the sampled pixels and a value of 0 represents the pixels that are not sampled. When there is no conditioning information, the mask is filled with zeros. If image $x$ has 3 channels, then the mask will be applied to all channels. The count sampling distribution is chosen to be a power law distribution with a high exponent so that the decoder can learn to handle also the cases where the conditioning information is not available. The exponent will be a hyperparameter of the model.

For the conditioning information $m$, I will implement a two-step sampling process:

\begin{enumerate}
    \item \textbf{Sampling the number of pixels:} In this step, the number of pixels to be sampled from the input image $x$ is sampled from a power law distribution. The power law distribution is scaled to the size of the input image $x$ and is used to sample the number of pixels to be sampled from the input image $x$.
    \item \textbf{Sampling the pixels:} In this step, the conditioning information $m$ is sampled from the input image $x$ by sampling the number of pixels sampled in the previous step from the input image $x$ uniformly at random or from a Gaussian distribution, which can be seen in Figure~\ref{SamplingFigure}.
\end{enumerate}

\subsection{Application to Gaussian VAEs}

In Gaussian VAEs, applying the second method involves modifying the decoder to be capable of reconstructing the input data under variable conditioning. The modified decoder $p_\xi(x|z,m)$ is capable of reconstructing the input data based on the latent variable $z$ and the conditioning information $m$ or just the latent variable $z$.

This is achieved by using a fully connected layer to merge the latent variable $z$ and the conditioning information $m$ before passing it through the transposed convolutional layers. The architecture of the Gaussian VAEs framework with a single decoder capable of variable conditioning is illustrated in Figure~\ref{SCVAE1DFigure}.



\begin{figure}[H]
    \centering
    \input{figures/scvae1d.tex}
    \caption[\method{2} applied to Gaussian VAEs.]%
    {
        \methodTwo\ applied to Gaussian VAEs. The Gaussian VAEs framework is modified by allowing the decoder to be conditioned on a variable amount of information and to dynamically adjust its behavior based on the amount of information present in the variable $m$. The input $x$ is passed through the encoder with parameters $\phi$ producing the mean $\mu$ and the standard deviation $\sigma$ of the Gaussian distribution. The random variable $\epsilon$ is sampled from a standard Gaussian distribution and is used to sample $ z = \mu + \sigma \odot \epsilon$. The sampled $z$ is then used as input to the decoder as well as the extra conditioning information $m$. With this approach there is no need for a second decoder, as the single decoder is capable to reconstruct the data based on the latent variable $z$ and the conditioning information $m$ or just the latent variable $z$.
    }\label{SCVAE1DFigure}
\end{figure}

\subsection{Application to VQ-VAEs}

In VQVAEs, same as in Gaussian VAEs, the second method involves modifying the decoder to be capable to receive variable conditioning information. Unlike Gaussian VAEs, the VQ-VAEs use Vector Quantization to discretize the continuous latent space. Because of this, the latent variable $z$ can not be directly merged with the conditioning information $m$ using a fully connected layer. Instead, the corresponding embedding table vectors $z_q(x)$ must be computed for the latent variable $z$ before merging it with the conditioning information $m$. The architecture of the VQ-VAEs framework with a single decoder capable of variable conditioning is illustrated in Figure~\ref{SCVQVAE1DFigure}.

\begin{figure}[H]
    \centering
    \input{figures/scvqvae1d.tex}
    \caption[\method{2} applied to VQ-VAEs.]%
    {
        \methodTwo\ applied to VQ-VAEs. The VQ-VAEs framework is modified by allowing the decoder to be conditioned on a variable amount of information and to dynamically adjust its behavior based on the amount of information present in the variable $m$. The input $x$ is passed through the encoder producing the output $z_e(x)$. The output $z_e(x)$ is then used as input to the autoregressive model to generate the latent variable $z$. The latent variable $z$ is then used as input to the decoder as well as the extra conditioning information $m$. With this approach there is no need for a second decoder, as the single decoder is capable to reconstruct the data based on the latent variable $z$ and the conditioning information $m$ or just the latent variable $z$.
    }\label{SCVQVAE1DFigure}
\end{figure}


\begin{figure}
    \centering
    \input{figures/sampling.tex}
    \caption[Table of pixel sampling types for conditioning.]%
    {
        Table of pixel sampling types for conditioning. The table has 3 rows each representing a different sampling type. The first row represents the exact same sampling type, the second row represents the uniform random sampling type and the third row represents the Gaussian sampling type where the pixels are more likely to be sampled from the center of the image. The first column represents the original image, the second column represents the mask and the third column represents the result of the sampling operation.
    }\label{SamplingFigure}
\end{figure}


