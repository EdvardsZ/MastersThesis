{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# load mnist\n",
    "train_ds = MNIST('data', train=True, download=True, transform=ToTensor())\n",
    "test_ds = MNIST('data', train=False, download=True , transform=ToTensor())\n",
    "\n",
    "# create data loaders\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=12)\n",
    "val_loader = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=12)\n",
    "\n",
    "sample = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim=16):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, latent_dim, 1, padding=0)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32, 16, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "print(sample[0].shape)\n",
    "\n",
    "encoder = Encoder()\n",
    "out = encoder(sample[0])\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim=16):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dim, 64, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 1, 3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.decoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "randn = torch.randn(32, 16, 7, 7)\n",
    "decoder = Decoder()\n",
    "out = decoder(randn)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorQuantizer(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, beta=0.25):\n",
    "        super(VectorQuantizer, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.num_embeddings = num_embeddings\n",
    "        self.beta = beta\n",
    "\n",
    "        w_init = torch.nn.init.uniform_\n",
    "        self.embeddings = nn.Parameter(w_init(torch.empty(self.embedding_dim, self.num_embeddings)))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        input_shape = x.shape\n",
    "        flattened = x.view(-1, self.embedding_dim)\n",
    "\n",
    "        encoding_indices = self.get_code_indices(flattened)\n",
    "        encodings = F.one_hot(encoding_indices, num_classes=self.num_embeddings).to(flattened.device)\n",
    "        quantized = torch.matmul(encodings.float(), self.embeddings.t())\n",
    "\n",
    "        quantized = quantized.view(input_shape)\n",
    "\n",
    "        commitment_loss = torch.mean((quantized.detach() - x) ** 2)\n",
    "        codebook_loss = torch.mean((quantized - x.detach()) ** 2)\n",
    "        self.loss = self.beta * commitment_loss + codebook_loss\n",
    "\n",
    "        quantized = x + (quantized - x).detach()\n",
    "        return quantized\n",
    "\n",
    "    def get_code_indices(self, flattened_inputs):\n",
    "        similarity = torch.matmul(flattened_inputs, self.embeddings)\n",
    "        distances = (torch.sum(flattened_inputs ** 2, dim=1, keepdim=True)\n",
    "                     + torch.sum(self.embeddings ** 2, dim=0)\n",
    "                     - 2 * similarity)\n",
    "\n",
    "        encoding_indices = torch.argmin(distances, dim=1)\n",
    "        return encoding_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_masters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
