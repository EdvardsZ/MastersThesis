{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12, 3, 32, 32])\n",
      "torch.Size([12288])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (12288x65536 and 12288x3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Home/siv34/edzak2974/projects/MastersThesis/src_2/test.ipynb Cell 1\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbirget/Home/siv34/edzak2974/projects/MastersThesis/src_2/test.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=30'>31</a>\u001b[0m encodings \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mone_hot(encoding_indices, num_classes\u001b[39m=\u001b[39m\u001b[39m65536\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbirget/Home/siv34/edzak2974/projects/MastersThesis/src_2/test.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39m# encodings.shape = (batch_size * height * width, num_embeddings)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bbirget/Home/siv34/edzak2974/projects/MastersThesis/src_2/test.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=33'>34</a>\u001b[0m quantized \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(encodings\u001b[39m.\u001b[39;49mfloat(), embeddings\u001b[39m.\u001b[39;49mt())\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbirget/Home/siv34/edzak2974/projects/MastersThesis/src_2/test.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=34'>35</a>\u001b[0m  \u001b[39m# quantized.shape = (batch_size * height * width, embedding_dim)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bbirget/Home/siv34/edzak2974/projects/MastersThesis/src_2/test.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m quantized \u001b[39m=\u001b[39m quantized\u001b[39m.\u001b[39mview(input_shape) \u001b[39m# Take this for the loss\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (12288x65536 and 12288x3)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# import cifar10 dataset, dataloader\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=12, shuffle=True, num_workers=2)\n",
    "\n",
    "images = next(iter(train_loader))[0]\n",
    "\n",
    "print(images.shape)\n",
    "\n",
    "input_shape = images.shape\n",
    "\n",
    "flatened = images.view(-1, 3)\n",
    "\n",
    "# embddings copy of flatened\n",
    "embeddings = flatened.detach().clone().T\n",
    "\n",
    "similarity = torch.matmul(flatened, embeddings)\n",
    "distances = (torch.sum(flatened ** 2, dim=1, keepdim=True)\n",
    "                + torch.sum(embeddings ** 2, dim=0)\n",
    "                - 2 * similarity)\n",
    "\n",
    "encoding_indices = torch.argmin(distances, dim=1)\n",
    "\n",
    "print(encoding_indices.shape)\n",
    "\n",
    "encodings = F.one_hot(encoding_indices, num_classes=12288)\n",
    "# encodings.shape = (batch_size * height * width, num_embeddings)\n",
    "\n",
    "quantized = torch.matmul(encodings.float(), embeddings.t())\n",
    " # quantized.shape = (batch_size * height * width, embedding_dim)\n",
    "\n",
    "quantized = quantized.view(input_shape) # Take this for the loss\n",
    "# quantized.shape = (batch_size, embedding, height, width)\n",
    "\n",
    "print(quantized.shape)\n",
    "# plot restored and original with matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].imshow(images[3].permute(1, 2, 0))\n",
    "ax[1].imshow(quantized[3].permute(1, 2, 0))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(flatened.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_masters",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
